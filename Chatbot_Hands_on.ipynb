{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
  },

  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Chatbot with Agentic-RAG with LLM Api call**"
      ],
      "metadata": {
        "id": "nef-1JIm_ES0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install necessary libraries"
      ],
      "metadata": {
        "id": "17hsY1QE_Z91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community langchain-core langchain-groq langchain-huggingface pypdf faiss-cpu sentence-transformers requests"
      ],
      "metadata": {
        "id": "-FJoLYxe5jt2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d03ba5-63f7-4942-8a32-42d653515c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.79)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.0.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-1.0.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.2.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.40)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.33.0-py3-none-any.whl.metadata (16 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-groq to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.36.0)\n",
            "INFO: pip is looking at multiple versions of langchain-huggingface to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-1.0.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.22.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n",
            "Downloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
            "Downloading pypdf-6.2.0-py3-none-any.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.6/326.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.33.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, pypdf, mypy-extensions, marshmallow, faiss-cpu, typing-inspect, groq, dataclasses-json, langchain-huggingface, langchain-groq, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss-cpu-1.12.0 groq-0.33.0 langchain-community-0.3.31 langchain-groq-0.3.8 langchain-huggingface-0.3.1 marshmallow-3.26.1 mypy-extensions-1.1.0 pypdf-6.2.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Enter Groq API Key for using LLM without loading to cloud"
      ],
      "metadata": {
        "id": "037yIysT_ipa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"Your_api_key\"\n"
      ],
      "metadata": {
        "id": "Pn4Wy-HW_Bnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Importing necessary libraries"
      ],
      "metadata": {
        "id": "nxHNxCRo_yUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import requests\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import Tool, initialize_agent\n",
        "from langchain.memory import ChatMessageHistory\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n"
      ],
      "metadata": {
        "id": "DhroqFC0_yn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Download PDF - Attention Is All You Need paper"
      ],
      "metadata": {
        "id": "vOH95iW_Bvyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_url = \"https://arxiv.org/pdf/1706.03762.pdf\"\n",
        "pdf_file = \"attention-is-all-you-need.pdf\"\n",
        "if not os.path.exists(pdf_file):\n",
        "    pdf = requests.get(pdf_url)\n",
        "    with open(pdf_file, \"wb\") as f:\n",
        "        f.write(pdf.content)"
      ],
      "metadata": {
        "id": "BcUnfyOVAQw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Load & Split PDF into chunks"
      ],
      "metadata": {
        "id": "IdC-xXRcBefe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(pdf_file)\n",
        "documents = loader.load()\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size = 3000, chunk_overlap = 450)\n",
        "chunks = splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "dZiIU_DqAX8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Embed & Create Vector Store"
      ],
      "metadata": {
        "id": "6fE2TI3ZB8Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "retriever = vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "3JOuf6P-AaDX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "b2f653babdd64f0f88f879540bb8b14e",
            "0c972b3914744ad397eae506f885dce3",
            "4cabc901a67f418e870a4fea0d47a096",
            "8f95eb3972d14bc1938077393862d5da",
            "4bc7d741c4c148d88d6d2d2534d4e51b",
            "30f056f756cc4ba1a259ab69e76e21ac",
            "a7a7ca78cb4c4dcbb14bd8423641b965",
            "b99c08ca9a3e48518d517b56dac15ef4",
            "3f6fd29ddb4f4782983cdac639de46a5",
            "09b266ccaf7d4952a40fb60207dab807",
            "c86d625a203e471a89419a59028b7b05",
            "ed17041d073c48caa811865861c750d9",
            "daf6ef8164ec4a698fe1633e4ecfd191",
            "6372ddb75418446ebad4ba9d2b29380b",
            "abe1b0f8055f41e380b9c5e33a9b7304",
            "f318d2fe8eb34a4fa93a86850faf2380",
            "1d5c40c3bbda4bf693c5b471d99da05c",
            "0f33c15159974e80946896892c320d51",
            "bb7a4cfb1e9c40cf98ccce811e687253",
            "fcbbf130230c4eaea8424d4cd39d91bc",
            "4062a87b86b84096932131852b90ad1e",
            "2a56260b86c24c0a985e118459ad3a5c",
            "d8e38f3787a14530b3f3bbd2fdd2c1b8",
            "447b84cd88554358baeaab71089e1c61",
            "2222689f18d649a79c16d5585a7516cd",
            "beaa73f53cff41c2867e6cf3bd2aabc7",
            "9fd3049530c04f758c06d60638cb84f6",
            "2a81c3ea11ef4033b03da133abda4456",
            "b547c6de223d4eac872f1c8bb560ec8b",
            "bf80ba33c05c4f53b6a3360f68eaae92",
            "2580d22d9a824503ab108ee63519658b",
            "e7b56d6033644a2e9c1f0a4213914b88",
            "f7d45a8ee63b4756a8b4f93d2f91b15e",
            "747d2dbef704441396c2522ceff92dba",
            "54b052b0d0194e79b3d9541c652230e5",
            "ae48d032e1964c2d8b1582804b4d2633",
            "76966dd5854f4722963fa016f139b7bc",
            "79120e57a8d440138e6a52e241c9ea7c",
            "2f627a5a19e142c99444fc1acceb3004",
            "546485da577940e78afc33f5912dee1b",
            "cb193d1007fd44a196ecf84d0714ecb8",
            "eb33e23866134e37a08eee549cc1608a",
            "36ca3d8e215b42afbbf9c7cd30c7f31a",
            "1eadf1b6e4c94267938b7c2f4d5cd12b",
            "8231e565b2bd49a685ce00f7dbd0827d",
            "dee65a2d325345428c7d70b9bdddb9b4",
            "3f8238e391034fbca6aec6e27e27acef",
            "6ca56a329e5a444fbf9242a1a955c2d2",
            "3859fc8ca71441c3bb0ebec34815f5ba",
            "da0e778c9a244998812c0d7bd016c8b1",
            "a554b4c43b024941ba65c6992186c22c",
            "8f0abfb5405c48c38e205a769674c838",
            "eea2d3167a16414d9a6ce795d46d5df6",
            "374b054ee90f42968551e2aa257d7310",
            "ed8b407f38ed4b76912228b5d222b440",
            "e447719597ca4077a0949fffe660f7ae",
            "bc64890ee07f4f7c9291dec6413b35fe",
            "08037fac302c4273a84a85aab760a227",
            "a43b2a2315824da0b04e13eb08623672",
            "818771413d014202bfa56d5253d64936",
            "29ab5696be584903b810a3681a1ec465",
            "112f9df4db9e4809aed3ea6a5f74d53b",
            "f75becaf8f084595aa8a1f71cc2ab371",
            "5d04edd7d01a40f09267400b883b7e48",
            "30c48d5c6f734db195fd717ebf906f28",
            "b80f35cc76404b3f973b2309a6d687cd",
            "5a94cb4c17064562879d123275a39ad4",
            "86d7078142914d9298d945c4beec9d50",
            "f8afe0aff20c4a21843889041fe06cd8",
            "3fbeeff14b8e4fbeb3fc366f2ef04fe8",
            "05d46b1cf6bd411baae5a6a3b5d0e093",
            "cd3a5b839f8541a99999a9eb00482a7c",
            "ff96e088e3264645b7a82cdd2e02670b",
            "71b43a4541994b7cba1e63476884e7fc",
            "8187679e073543f9a7392d1d75aad5bb",
            "1e6efee12c6f4c2288ff6d9e1297b65b",
            "a935b144ad9541df9c14be89edd7d2e3",
            "571e7d7f8e9b44b3878fb84db1f1e5d5",
            "a9cc696950d54d08b1128bc51cfe61f9",
            "c58f37de8bd5449aaef5b99f99041b38",
            "6b027781239546b5805a10818a42b85b",
            "bf6f1854522c4d54a37be5bb120a6deb",
            "0f5fb9f792974b7b98d8c7e8e805f70e",
            "040857c256784a34bac3d4cffd072594",
            "c47e0939c0884611a665bd3d64d92b3f",
            "d8c22b5b4f464a09a6a6e7ccab0122c4",
            "5b4dd07fe0f4458facee4f6305b534f5",
            "f1ad41e710d1424f97bfce05c426455e",
            "82bdb8a945d74d1496e34d28a92776b5",
            "8e978d455ac3457dadde39b1861fad3c",
            "af7f0bc89e7749cebb44aef7853b869f",
            "0b25c242961646fdadc9284a042c864e",
            "bb84bc449cf24237bea3ab51a019cc44",
            "53e747a7bc46425aa154e88840cea5cc",
            "c1d439d806244a2f85ca990d28e0fe28",
            "1a083fad7afb445c921d40094d2a7f77",
            "d26f4ae3bbac41dc96a0809af73058d7",
            "622504762c38407c9fcd2f571aabb1af",
            "9cc47dde72cd4a0a87d32e5e8297e864",
            "62e422c00e634ca386e7d596cdbd613b",
            "ae4a97af082d4d6b902d254df555773b",
            "0a850407e3d6437db207a61869f34ce8",
            "a1e88afeb01a41e397956286997e4921",
            "0c2448b745194879847e5252f0724ce6",
            "f93f2d3b02eb4825b4ba41fcd5684c05",
            "94aaa06a34d14b4ba78d360b23873273",
            "03c82cb555ed4758bbf93af67dd2ee02",
            "3f3176a402be497083d6f77ff4a69c97",
            "f405549a3a6a4445840c6a133a16ad13",
            "0b03aecaa3574b90ab502580032a9043",
            "e0f512bf27a8480294bcba0b25f43450",
            "d16eb7a615524c3ea8af162aa986cd11",
            "0f42cd3522264371bd0ee91b507adcfb",
            "ea0b9a2aeefe4e0bb6afa5026cc9211e",
            "db963fb47e334821aae103936fe95021",
            "77c4f62bcf034191b60133057497489d",
            "4236a061658540d7b505448e72288db1",
            "3f78647707b04f309ebde914a9c96640",
            "3cf0b8375e27423e83d691660a0d969f",
            "42d1decfd72549ffbb5b328d5d419952",
            "d8b85cf2af5a44a390b5013bf82ee0f1"
          ]
        },
        "outputId": "a11dd372-03f2-4dad-f286-6b22553c3a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2f653babdd64f0f88f879540bb8b14e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed17041d073c48caa811865861c750d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8e38f3787a14530b3f3bbd2fdd2c1b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "747d2dbef704441396c2522ceff92dba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8231e565b2bd49a685ce00f7dbd0827d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e447719597ca4077a0949fffe660f7ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a94cb4c17064562879d123275a39ad4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "571e7d7f8e9b44b3878fb84db1f1e5d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82bdb8a945d74d1496e34d28a92776b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62e422c00e634ca386e7d596cdbd613b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0f512bf27a8480294bcba0b25f43450"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Load Groq LLM"
      ],
      "metadata": {
        "id": "CNKK50zUCAfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm = ChatGroq(model=\"openai/gpt-oss-20b\", temperature=0)\n"
      ],
      "metadata": {
        "id": "KUPN0llkAfLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. RAG-based Conversational QA Chain provided as a Tool to our Agent -> Agentic Rag"
      ],
      "metadata": {
        "id": "_AAbqLxDCFcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"PDF_QA\",\n",
        "        func=lambda q: qa_chain.invoke({\"question\": q, \"chat_history\": []})[\"answer\"],\n",
        "        description=\"Use this to answer questions based on the loaded PDF.\"\n",
        "    )\n",
        "]\n"
      ],
      "metadata": {
        "id": "2UcHvkUi_-lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Enable chat memory"
      ],
      "metadata": {
        "id": "MJek5iKwCopS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    chat_memory=chat_history,\n",
        "    return_messages=True\n",
        ")"
      ],
      "metadata": {
        "id": "xJuuHOE4Aqon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Create Agent"
      ],
      "metadata": {
        "id": "atuDtFHUCrfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=\"chat-conversational-react-description\",\n",
        "    memory=memory,\n",
        "    verbose=False,\n",
        "    system_message=(\n",
        "        \"You are an AI assistant that MUST answer questions using the tool 'PDF_QA' \"\n",
        "        \"which retrieves information from the research paper. \"\n",
        "        \"You are NOT allowed to answer from your general knowledge. \"\n",
        "        \"Every answer must clearly say: 'Tool used: PDF_QA'. \"\n",
        "        \"If the tool does not provide an answer, say 'The PDF does not contain this information'.\"\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "DbEqLQtPAuZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Start chat loop!\n"
      ],
      "metadata": {
        "id": "ldCMO0sLCviB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    question = input(\"\\nYou: \")\n",
        "    if question.lower() == \"exit\":\n",
        "        break\n",
        "    if not question.strip():\n",
        "        continue\n",
        "    response = agent.invoke({\"input\": question})\n",
        "    print(\"\\nBot:\", response[\"output\"])"
      ],
      "metadata": {
        "id": "aUwT72kd5TnT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "334cae5d-3b05-4d9a-d8cf-c58fe03f0934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You: which tools do you have?\n",
            "\n",
            "Bot: I have the following tool: PDF_QA\n",
            "\n",
            "You: explain transformers using pdf_qa \n",
            "\n",
            "Bot: Based on the retrieved information, here is a detailed explanation of transformers:\n",
            "\n",
            "**Transformers** are a family of neural network models that have become the de‑facto standard for many sequence‑to‑sequence tasks (machine translation, summarization, language modeling, etc.).  The original Transformer paper (“Attention Is All You Need”, 2017) introduced a new architecture that relies almost entirely on *attention* mechanisms, discarding the recurrent and convolutional layers that dominated the field for years.\n",
            "\n",
            "---\n",
            "\n",
            "## 1.  Overall Architecture\n",
            "\n",
            "The Transformer is split into two main parts:\n",
            "\n",
            "| Part | Purpose | Key Sub‑layers |\n",
            "|------|---------|----------------|\n",
            "| **Encoder** | Processes the input sequence and produces a continuous representation. | 1. Multi‑head self‑attention  <br> 2. Position‑wise feed‑forward network |\n",
            "| **Decoder** | Generates the output sequence one token at a time, conditioned on the encoder output and the tokens generated so far. | 1. Masked multi‑head self‑attention  <br> 2. Multi‑head attention over encoder output  <br> 3. Position‑wise feed‑forward network |\n",
            "\n",
            "Both encoder and decoder are built from *identical* layers stacked on top of each other (the paper uses **N = 6** layers for the base model, **N = 6** for the “big” model, but the number can be changed).\n",
            "\n",
            "Each sub‑layer is wrapped in a **residual connection** followed by **layer normalization**:\n",
            "\n",
            "```\n",
            "output = LayerNorm(x + Sublayer(x))\n",
            "```\n",
            "\n",
            "This pattern stabilises training and allows very deep models.\n",
            "\n",
            "All sub‑layers, as well as the embedding layers, output vectors of the same dimensionality **d_model** (512 for the base model, 1024 for the big model).  This uniformity lets the residual connections simply add the input and output of each sub‑layer.\n",
            "\n",
            "---\n",
            "\n",
            "## 2.  Attention Mechanism\n",
            "\n",
            "### 2.1  What is attention?\n",
            "\n",
            "An attention function takes a **query** vector and a set of **key–value** pairs and produces an output that is a weighted sum of the values.  The weights are computed by comparing the query to each key (typically via a dot product), normalising with a softmax, and then using those probabilities to weight the values.\n",
            "\n",
            "Mathematically:\n",
            "\n",
            "```\n",
            "Attention(Q, K, V) = softmax(Q Kᵀ / √d_k) V\n",
            "```\n",
            "\n",
            "where `d_k` is the dimensionality of the keys (used for scaling).\n",
            "\n",
            "### 2.2  Multi‑head attention\n",
            "\n",
            "Instead of a single attention operation, the Transformer splits the queries, keys, and values into **h** “heads”, each with its own linear projections.  Each head learns to focus on different aspects of the input.  The outputs of all heads are concatenated and projected back to `d_model` dimensions.\n",
            "\n",
            "This gives the model a richer representation while keeping the computational cost manageable.\n",
            "\n",
            "### 2.3  Self‑attention\n",
            "\n",
            "- **Encoder self‑attention**: Every token attends to every other token in the input.  This allows the model to capture long‑range dependencies without recurrence.\n",
            "- **Decoder self‑attention**: Same as encoder, but *masked* so that a position can only attend to earlier positions.  This ensures the model can only use information that would be available at that point during generation.\n",
            "\n",
            "### 2.4  Encoder–decoder attention\n",
            "\n",
            "The decoder’s third sub‑layer attends over the encoder’s output.  This lets the decoder “look back” at the source sentence while generating each target token.\n",
            "\n",
            "---\n",
            "\n",
            "## 3.  Feed‑Forward Networks\n",
            "\n",
            "After each attention sub‑layer, a **position‑wise feed‑forward network** is applied independently to every position.  It consists of two linear layers with a ReLU (or GELU) activation in between:\n",
            "\n",
            "```\n",
            "FFN(x) = max(0, x W₁ + b₁) W₂ + b₂\n",
            "```\n",
            "\n",
            "The hidden dimension `d_ff` is usually larger than `d_model` (e.g., 2048 for the base model).  This component adds non‑linearity and increases the model’s capacity.\n",
            "\n",
            "---\n",
            "\n",
            "## 4.  Positional Encoding\n",
            "\n",
            "Because the Transformer has no recurrence or convolution, it needs a way to inject information about the order of tokens.  The original paper uses **sinusoidal positional encodings**:\n",
            "\n",
            "```\n",
            "PE(pos, 2i)   = sin(pos / 10000^(2i/d_model))\n",
            "PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
            "```\n",
            "\n",
            "These are added to the input embeddings before the first encoder/decoder layer.  The sinusoidal form has the property that any relative position can be represented as a linear function of the absolute positions, which helps the model generalise to longer sequences.\n",
            "\n",
            "Later work has also experimented with learned positional embeddings, but the sinusoidal version works well and requires no extra parameters.\n",
            "\n",
            "---\n",
            "\n",
            "## 5.  Regularisation & Training Tricks\n",
            "\n",
            "| Technique | Purpose | How it’s applied |\n",
            "|-----------|---------|------------------|\n",
            "| **Dropout** | Prevents over‑fitting | Applied to the output of each sub‑layer, to the sum of embeddings + positional encodings, and to the attention weights.  The base model uses a dropout rate of 0.1; the big model uses 0.3. |\n",
            "| **Label smoothing** | Encourages the model to be less confident, improving generalisation | A small amount (ε = 0.1) is added to the target distribution during training. |\n",
            "| **Residual dropout** | Dropout applied after the residual addition but before layer norm | Helps the model learn more robust representations. |\n",
            "| **Checkpoint averaging** | Improves final performance | For the base model, the last 5 checkpoints are averaged; for the big model, the last 20. |\n",
            "| **Beam search + length penalty** | Decoding strategy | Beam size 4, length penalty α = 0.6. |\n",
            "\n",
            "---\n",
            "\n",
            "## 6.  Variations & Ablations (from the paper)\n",
            "\n",
            "| Variation | What was changed | Effect |\n",
            "|-----------|------------------|--------|\n",
            "| **Number of heads / key/value size** | Tested 1, 4, 16, 32 heads; varied `d_k` and `d_v` | Too few heads hurts performance; too many heads also degrades quality. |\n",
            "| **Dropout rate** | 0.0 vs 0.2 | Dropout is very helpful; 0.2 improves BLEU. |\n",
            "| **Positional encoding type** | Sinusoidal vs learned | Nearly identical results. |\n",
            "| **Model size** | `d_model` 512 vs 1024, `d_ff` 2048 vs 4096 | Larger models yield better BLEU but cost more compute. |\n",
            "\n",
            "---\n",
            "\n",
            "## 7.  Why Transformers Work\n",
            "\n",
            "1. **Parallelism** – All tokens are processed simultaneously; no sequential dependencies as in RNNs, enabling efficient GPU utilisation.\n",
            "2. **Long‑range dependencies** – Self‑attention directly connects any two positions, regardless of distance.\n",
            "3. **Expressive power** – Multi‑head attention and deep feed‑forward layers give the model a large capacity to learn complex patterns.\n",
            "4. **Simplicity** – The architecture is relatively simple to implement and tune compared to deep RNNs or CNNs.\n",
            "\n",
            "---\n",
            "\n",
            "## 8.  Practical Impact\n",
            "\n",
            "The Transformer achieved state‑of‑the‑art BLEU scores on WMT 2014 English‑to‑German (27.3 for the base model, 28.4 for the big model) and English‑to‑French (38.1 base, 41.8 big) while training at a fraction of the cost of previous models.  Its design has spawned a family of variants (BERT, GPT, T5, etc.) that dominate many NLP benchmarks today.\n",
            "\n",
            "---\n",
            "\n",
            "### TL;DR\n",
            "A Transformer is a sequence‑to‑sequence model built from stacked layers of multi‑head self‑attention and feed‑forward networks, wrapped in residual connections and layer normalisation.  It uses positional encodings to inject order information and relies on attention to capture dependencies across the entire sequence.  Its parallel, non‑recurrent design makes it fast to train and highly effective for a wide range of language tasks.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2996081633.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nYou: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Congratulations🎉 You have created your first Chatbot !!!"
      ],
      "metadata": {
        "id": "R7xgSsmDF7fW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Optional) This is a Gradio UI for better Looking outputs"
      ],
      "metadata": {
        "id": "sndaewuyDPee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "P9SHvKDbDasS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a6d391-d562-4f36-bb15-4a8ec08f28d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.121.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.4)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "new_qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
        "\n",
        "def chat_with_pdf(query, history):\n",
        "    response = new_qa_chain.invoke({\"question\": query, \"chat_history\": []})\n",
        "    return history + [(query, \"Tool used: PDF_QA\\n\\n\" + response['answer'])]\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox(label=\"Ask a question about the PDF\")\n",
        "    msg.submit(chat_with_pdf, [msg, chatbot], [chatbot])\n",
        "    msg.submit(lambda: \"\", None, msg)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "OmZ7aNyMJLy6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "fe8ae410-c5ac-4117-d363-11d631660401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1809937034.py:9: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://129712ffd5e2f736c9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://129712ffd5e2f736c9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}
